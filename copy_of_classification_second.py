# -*- coding: utf-8 -*-
"""Copy of Classification_second.ipynb


Original file is located at
    https://colab.research.google.com/drive/1xcLMt9aSZOcNH14Q9WZz7gXnbqR7_gMk

# **This is to train a simple nail biting classification model based on internet and "11k Hands" data with two categories.**

# Step1: dataloading and preprocessing
"""

from google.colab import drive
drive.mount('/content/drive')

from fastai.vision.all import *
from pathlib import Path
path = Path('/content/drive/MyDrive/nail_data/classification_model_2')

dls = ImageDataLoaders.from_folder(
    path,
    train='train',
    valid='valid',
    item_tfms=[Resize(192, method='squish')]
)

"""# Step2: Check the data"""

dls.show_batch(max_n=6, nrows=2)

"""# Step3: Train the model"""

learn = vision_learner(dls, resnet34, metrics=[Precision(),Recall(),accuracy,F1Score()])

learn.fine_tune(10, base_lr=1e-3)

"""# Step4: Save the model"""

learn.export('/content/drive/MyDrive/nail_data/trained_models/nail_bitten_classifier_2.pkl')

interp = ClassificationInterpretation.from_learner(learn)
interp.plot_confusion_matrix()

"""# Step 6: Experimenting with different presizing techniques"""

#æ”¹è¿›ç‰ˆæœ¬1ï¼šåŸºç¡€presizing
dls = ImageDataLoaders.from_folder(
    path,
    train='train',
    valid='valid',
    item_tfms=[Resize(460)],  # å…ˆresizeåˆ°å¤§å°ºå¯¸ï¼Œé»˜è®¤crop
    batch_tfms=aug_transforms(size=192, min_scale=0.75)  # GPUä¸Šæ•°æ®å¢å¼º+æœ€ç»ˆresize
)

learn = vision_learner(dls, resnet34, metrics=[Precision(),Recall(),accuracy,F1Score()])

learn.fine_tune(10, base_lr=1e-3)

#æ”¹è¿›ç‰ˆæœ¬2ï¼šé’ˆå¯¹æŒ‡ç”²ä¼˜åŒ–

dblock = DataBlock(
    blocks=(ImageBlock, CategoryBlock),
    get_items=get_image_files,
    get_y=parent_label,  # ä»æ–‡ä»¶å¤¹åè·å–æ ‡ç­¾
    splitter=GrandparentSplitter(train_name='train', valid_name='valid'),
    item_tfms=Resize(460),
    batch_tfms=aug_transforms(
        size=192,
        min_scale=0.8,
        max_rotate=10,
        max_zoom=1.1,
        max_warp=0.1,
        flip_vert=False
    )
)

dls = dblock.dataloaders(path, bs=16)

learn = vision_learner(dls, resnet34, metrics=[Precision(),Recall(),accuracy,F1Score()])

learn.fine_tune(10, base_lr=1e-3)

"""# Step 7: Experimenting with different learning rate"""

# 1. åˆ›å»ºlearnerï¼ˆä½†ä¸è¦è®­ç»ƒï¼‰
learn = vision_learner(dls, resnet34, metrics=[Precision(),Recall(),accuracy,F1Score()])

# 2. è¿è¡Œlr_find
learn.lr_find()

#Valley Pointï¼ˆFastAIæ¨èï¼‰
learn.fine_tune(10, base_lr=5.75e-4)

#ç¨å¾®æ¿€è¿›ä¸€ç‚¹ (æœ€é™¡ä¸‹é™åŒºåŸŸå·¦ä¾§)
learn.fine_tune(10, base_lr=1e-4)

learn.fine_tune(10, base_lr=2e-3)

learn.fine_tune(10, base_lr=3e-3)

learn.fine_tune(10, base_lr=5e-3)

learn.fine_tune(10, base_lr=7e-3)

learn.fine_tune(10, base_lr=7e-3)

"""# Step 8: Experimenting with different discriminative learning rates"""

#æ ‡å‡†Discriminative LR
learn = vision_learner(dls, resnet34, metrics=[Precision(),Recall(),accuracy,F1Score()])

# ç¬¬ä¸€é˜¶æ®µï¼šå†»ç»“é¢„è®­ç»ƒå±‚ï¼Œåªè®­ç»ƒåˆ†ç±»å¤´
learn.fit_one_cycle(3, 3e-3)

# ç¬¬äºŒé˜¶æ®µï¼šè§£å†»å¹¶ä½¿ç”¨discriminative learning rates
learn.unfreeze()
learn.fit_one_cycle(12, lr_max=slice(1e-6, 1e-4))

# æ›´æ¿€è¿›çš„èŒƒå›´ï¼ˆåŸºäºä½ çš„lr_findç»“æœï¼‰
learn.fit_one_cycle(3, 3e-3)

learn.unfreeze()
# ä½¿ç”¨æ›´å¤§çš„å­¦ä¹ ç‡èŒƒå›´
learn.fit_one_cycle(12, lr_max=slice(5e-5, 3e-3))

#ä¸‰å±‚ä¸åŒå­¦ä¹ ç‡
learn.fit_one_cycle(3, 3e-3)

learn.unfreeze()
learn.fit_one_cycle(12, lr_max=slice(1e-6, 1e-5, 1e-4))

"""# Step 9: Experimenting with different architecture"""

# resnet50
learn = vision_learner(dls, resnet50, metrics=[Precision(),Recall(),accuracy,F1Score()])

learn.fine_tune(10, base_lr=1e-3)

# EfficientNet-B0 - æ•ˆç‡å¾ˆé«˜çš„ç°ä»£æ¶æ„
learn = vision_learner(dls, efficientnet_b0, metrics=[Precision(),Recall(),accuracy,F1Score()])

learn.fine_tune(10, base_lr=1e-3)

"""# Step 10: See model performance with best presizing, learning rate and architecture"""

dls = ImageDataLoaders.from_folder(
    path,
    train='train',
    valid='valid',
    item_tfms=[Resize(460)],  # å…ˆresizeåˆ°å¤§å°ºå¯¸ï¼Œé»˜è®¤crop
    batch_tfms=aug_transforms(size=192, min_scale=0.75)  # GPUä¸Šæ•°æ®å¢å¼º+æœ€ç»ˆresize
)

learn = vision_learner(dls, efficientnet_b0, metrics=[Precision(),Recall(),accuracy,F1Score()])

learn.fine_tune(15, base_lr=3e-3)

learn = vision_learner(dls, resnet34, metrics=[Precision(),Recall(),accuracy,F1Score()])

learn.fine_tune(15, base_lr=3e-3)

learn = vision_learner(dls, efficientnet_b0, metrics=[Precision(),Recall(),accuracy,F1Score()])

learn.fine_tune(15, base_lr=7e-3)

"""# Step 11: Experimenting with progressive resizing"""

# åˆ›å»ºè·å–DataLoadersçš„å‡½æ•°
def get_dls(size, bs=16):
    return ImageDataLoaders.from_folder(
        path,
        train='train',
        valid='valid',
        item_tfms=[Resize(size, method='squish')],
        bs=bs
    )

# Stage 1: å°å°ºå¯¸å¿«é€Ÿè®­ç»ƒ
print("Stage 1: å°å°ºå¯¸è®­ç»ƒ (128x128)")
dls = get_dls(128, bs=32)  # å°å›¾åƒå¯ä»¥ç”¨æ›´å¤§çš„batch size
learn = vision_learner(dls, resnet34, metrics=[Precision(),Recall(),accuracy,F1Score()])
learn.fit_one_cycle(4, 3e-3)  # ç”¨ä½ æ‰¾åˆ°çš„æœ€ä½³å­¦ä¹ ç‡

# Stage 2: å¤§å°ºå¯¸ç²¾ç»†è®­ç»ƒ
print("Stage 2: å¤§å°ºå¯¸è®­ç»ƒ (224x224)")
learn.dls = get_dls(224, bs=16)  # å¤§å›¾åƒç”¨å°ä¸€ç‚¹çš„batch size
learn.fine_tune(6, 1e-3)  # æ›´ä½çš„å­¦ä¹ ç‡ç²¾ç»†è°ƒæ•´

# ä½¿ç”¨ä½ å‘ç°çš„æœ€ä½³å‚æ•°ç»„åˆ
def get_dls_optimized(size, bs=16):
    return ImageDataLoaders.from_folder(
        path,
        train='train',
        valid='valid',
        item_tfms=[Resize(460 if size > 192 else size)],  # å¤§å°ºå¯¸ç”¨presizing
        batch_tfms=aug_transforms(size=size, min_scale=0.75) if size > 192 else None,
        bs=bs
    )

# Stage 1: å°å°ºå¯¸ + ä½ çš„æœ€ä½³å­¦ä¹ ç‡
print("Stage 1: å°å°ºå¯¸è®­ç»ƒ (128x128)")
dls = get_dls_optimized(128, bs=32)
learn = vision_learner(dls, resnet34, metrics=[Precision(),Recall(),accuracy,F1Score()])
learn.fit_one_cycle(4, 3e-3)  # ä½ çš„æœ€ä½³å­¦ä¹ ç‡

# Stage 2: å¤§å°ºå¯¸ + æœ€ä½³presizing + æœ€ä½³å­¦ä¹ ç‡
print("Stage 2: å¤§å°ºå¯¸è®­ç»ƒ (192x192)")
learn.dls = get_dls_optimized(192, bs=16)
learn.fine_tune(6, 3e-3)  # ç»§ç»­ç”¨ä½ çš„æœ€ä½³å­¦ä¹ ç‡

# åˆ›å»ºè·å–DataLoadersçš„å‡½æ•°
def get_dls(size, bs=16):
    return ImageDataLoaders.from_folder(
        path,
        train='train',
        valid='valid',
        item_tfms=[Resize(size, method='squish')],
        bs=bs
    )

# å››é˜¶æ®µæ¸è¿›å¼è®­ç»ƒå‚æ•°
stages = [
    (96, 32, 3, 3e-3),   # (size, batch_size, epochs, lr)
    (128, 24, 4, 3e-3),
    (192, 16, 4, 2e-3),
    (224, 16, 6, 1e-3)   # æœ€åç”¨æ›´ä½å­¦ä¹ ç‡ç²¾ç»†è°ƒæ•´
]

print("ğŸš€ å¼€å§‹å››é˜¶æ®µProgressive Resizingè®­ç»ƒ")
print("="*60)

import gc

learn = None
for i, (size, bs, epochs, lr) in enumerate(stages):
    print(f"\nğŸ“ Stage {i+1}/4: {size}x{size}, batch_size={bs}, epochs={epochs}, lr={lr}")
    print("-" * 40)

    if learn is None:
        # ç¬¬ä¸€é˜¶æ®µï¼šåˆ›å»ºæ–°çš„learner
        print("âœ¨ åˆ›å»ºæ–°çš„learner...")
        dls = get_dls(size, bs)
        learn = vision_learner(dls, resnet34, metrics=[Precision(),Recall(),accuracy,F1Score()])
        print(f"ğŸ¯ å¼€å§‹Stage {i+1}è®­ç»ƒ...")
        learn.fit_one_cycle(epochs, lr)
    else:
        # åç»­é˜¶æ®µï¼šæ›¿æ¢DataLoaderså¹¶ç»§ç»­è®­ç»ƒ
        print("ğŸ”„ æ›´æ–°DataLoaders...")

        # æ¸…ç†GPUå†…å­˜
        torch.cuda.empty_cache()
        gc.collect()

        # æ›´æ–°DataLoaders
        learn.dls = get_dls(size, bs)

        print(f"ğŸ¯ å¼€å§‹Stage {i+1}è®­ç»ƒ...")
        learn.fit_one_cycle(epochs, lr)

    # æ˜¾ç¤ºå½“å‰é˜¶æ®µç»“æœ
    print(f"âœ… Stage {i+1} å®Œæˆ!")

print("\n" + "="*60)
print("ğŸ† å››é˜¶æ®µProgressive Resizingè®­ç»ƒå®Œæˆ!")
print("="*60)

# æ˜¾ç¤ºæœ€ç»ˆç»“æœï¼ˆå¯é€‰ï¼‰
print("\nğŸ“Š æœ€ç»ˆéªŒè¯ç»“æœ:")
learn.validate()

"""# Step 12: Experimenting with test time agumentation"""

learn.fine_tune(10, base_lr=1e-3)

print("\nğŸ” å¼€å§‹TTAæµ‹è¯•...")

# æ™®é€šéªŒè¯ç»“æœ
normal_results = learn.validate()
normal_acc = float(normal_results[2])
normal_precision = float(normal_results[0])
normal_recall = float(normal_results[1])
normal_f1 = float(normal_results[3])

# TTAå¢å¼ºé¢„æµ‹
preds_tta, targs = learn.tta()
tta_acc = accuracy(preds_tta, targs).item()

# è®¡ç®—TTAçš„å…¶ä»–æŒ‡æ ‡
preds_class = preds_tta.argmax(dim=1)
from sklearn.metrics import precision_score, recall_score, f1_score
tta_precision = precision_score(targs, preds_class, average='weighted')
tta_recall = recall_score(targs, preds_class, average='weighted')
tta_f1 = f1_score(targs, preds_class, average='weighted')

# ç»“æœå¯¹æ¯”
print(f"\nğŸ“Š ç»“æœå¯¹æ¯”:")
print(f"æ™®é€šéªŒè¯ - å‡†ç¡®ç‡: {normal_acc*100:.2f}%, F1: {normal_f1*100:.2f}%")
print(f"TTAå¢å¼º - å‡†ç¡®ç‡: {tta_acc*100:.2f}%, F1: {tta_f1*100:.2f}%")
print(f"ğŸš€ TTAæå‡: å‡†ç¡®ç‡ {(tta_acc-normal_acc)*100:+.2f}%, F1 {(tta_f1-normal_f1)*100:+.2f}%")

"""# Step 13: Experimenting with label smoothing"""

import timm
model = timm.create_model('resnet34', pretrained=True, num_classes=dls.c)
learn = Learner(dls, model,
                loss_func=LabelSmoothingCrossEntropy(),
                metrics=[Precision(),Recall(),accuracy,F1Score()])

learn.fine_tune(10, base_lr=1e-3)

"""# Step 14: Optimize weight_decay parameters"""

# å®éªŒä¸åŒçš„weight_decayå€¼
weight_decays = [0.01, 0.1, 0.3]  # é»˜è®¤æ˜¯0.01

results = []
for wd in weight_decays:
    print(f"\nğŸ§ª æµ‹è¯•Weight Decay = {wd}")

    learn = vision_learner(dls, resnet34, metrics=[Precision(),Recall(),accuracy,F1Score()])
    learn.fine_tune(10, base_lr=1e-3, wd=wd)

    # è®°å½•ç»“æœ
    val_results = learn.validate()
    accuracy_score = float(val_results[2]) * 100
    f1_score = float(val_results[3]) * 100

    results.append({
        'weight_decay': wd,
        'accuracy': accuracy_score,
        'f1': f1_score
    })

    print(f"å‡†ç¡®ç‡: {accuracy_score:.2f}%, F1: {f1_score:.2f}%")

# ç»“æœå¯¹æ¯”
print(f"\nğŸ“Š Weight Decayå¯¹æ¯”ç»“æœ:")
for result in results:
    print(f"WD={result['weight_decay']}: Acc={result['accuracy']:.2f}%, F1={result['f1']:.2f}%")

"""# Save a good performance model and test (progressive resizing)--not good enough"""

# åˆ›å»ºè·å–DataLoadersçš„å‡½æ•°
def get_dls(size, bs=16):
    return ImageDataLoaders.from_folder(
        path,
        train='train',
        valid='valid',
        item_tfms=[Resize(size, method='squish')],
        bs=bs
    )

# Stage 1: å°å°ºå¯¸å¿«é€Ÿè®­ç»ƒ
print("Stage 1: å°å°ºå¯¸è®­ç»ƒ (128x128)")
dls = get_dls(128, bs=32)  # å°å›¾åƒå¯ä»¥ç”¨æ›´å¤§çš„batch size
learn = vision_learner(dls, resnet34, metrics=[Precision(),Recall(),accuracy,F1Score()])
learn.fit_one_cycle(4, 3e-3)  # ç”¨ä½ æ‰¾åˆ°çš„æœ€ä½³å­¦ä¹ ç‡

# Stage 2: å¤§å°ºå¯¸ç²¾ç»†è®­ç»ƒ
print("Stage 2: å¤§å°ºå¯¸è®­ç»ƒ (224x224)")
learn.dls = get_dls(224, bs=16)  # å¤§å›¾åƒç”¨å°ä¸€ç‚¹çš„batch size
learn.fine_tune(6, 1e-3)  # æ›´ä½çš„å­¦ä¹ ç‡ç²¾ç»†è°ƒæ•´

learn.export('/content/drive/MyDrive/nail_data/trained_models/nail_bitten_classifier_2_good_performance.pkl')

interp = ClassificationInterpretation.from_learner(learn)
interp.plot_confusion_matrix()

"""#Test the model"""

import matplotlib.pyplot as plt
from PIL import Image, ImageDraw, ImageFont
import numpy as np

model_path = '/content/drive/MyDrive/nail_data/trained_models/nail_bitten_classifier_2.pkl'
learn = load_learner(model_path)

img_path = '/content/drive/MyDrive/nail_data/test_data/huien.JPG'
img = PILImage.create(img_path)

pred_class, pred_idx, probs = learn.predict(img)

confidence = probs[pred_idx].item() * 100

title = f"Prediction result: {pred_class} (Confidence coefficient: {confidence:.1f}%)"
print(title)

import json

# è¯»å–å¹¶æ¸…ç†notebook
def clean_notebook_metadata():
    # å‡è®¾ä½ çš„notebookæ–‡ä»¶åæ˜¯è¿™ä¸ª
    notebook_name = "Copy of Classification_second.ipynb"

    try:
        with open(notebook_name, 'r') as f:
            notebook = json.load(f)

        # æ¸…ç†widgets metadata
        if 'metadata' in notebook:
            if 'widgets' in notebook['metadata']:
                # é€‰é¡¹1: å®Œå…¨åˆ é™¤widgets metadata
                del notebook['metadata']['widgets']
                print("âœ… åˆ é™¤äº†widgets metadata")

        # ä¿å­˜æ¸…ç†åçš„notebook
        with open(notebook_name.replace('.ipynb', '_clean.ipynb'), 'w') as f:
            json.dump(notebook, f, indent=2)

        print("âœ… æ¸…ç†å®Œæˆï¼ä½¿ç”¨ _clean.ipynb æ–‡ä»¶")

    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")

clean_notebook_metadata()

import os
import json

# æŸ¥çœ‹å½“å‰ç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶
print("ğŸ“ å½“å‰ç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶ï¼š")
for file in os.listdir('.'):
    if file.endswith('.ipynb'):
        print(f"âœ… Notebookæ–‡ä»¶ï¼š{file}")
    else:
        print(f"ğŸ“„ å…¶ä»–æ–‡ä»¶ï¼š{file}")
